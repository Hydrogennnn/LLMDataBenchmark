#!/bin/bash
#SBATCH -J basic_eval_full_bs8
#SBATCH -p TDS
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gres=gpu:8
#SBATCH --cpus-per-task=32
#SBATCH -o logs/basic_eval_%j.out
#SBATCH -e logs/basic_eval_%j.err
#SBATCH --time=12:00:00

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs

echo "=========================================="
echo "ğŸš€ XLam Dataset Semantic Executability Evaluation (Batch=8)"
echo "    Dataset: xlam_60k.jsonl (60,000 samples)"
echo "    Metric: Semantic Executability (Full Dataset)"
echo "    Model: Qwen2.5-32B-Instruct"
echo "    GPUs: 8 (Accelerate Multi-GPU)"
echo "    Batch Size: 8"
echo "=========================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURM_JOB_NODELIST"
echo "Start Time: $(date)"
echo "=========================================="

# åˆå§‹åŒ– conda
source ~/anaconda3/etc/profile.d/conda.sh
conda activate base

# éªŒè¯ç¯å¢ƒ
echo -e "\nğŸ” Python ç¯å¢ƒ:"
which python
python --version

echo -e "\nğŸ“¦ æ£€æŸ¥ä¾èµ–:"
pip show transformers torch accelerate || echo "âš ï¸  éœ€è¦å®‰è£…ä¾èµ–"

# æ˜¾ç¤º GPU ä¿¡æ¯
echo -e "\nğŸ“Š GPU ä¿¡æ¯:"
nvidia-smi

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONUNBUFFERED=1
export TOKENIZERS_PARALLELISM=false

# è¿è¡Œå®Œæ•´è¯„ä¼°
echo -e "\nğŸ”¥ å¼€å§‹è¿è¡Œå®Œæ•´åŸºç¡€è¯„ä¼°ï¼ˆbatch=8ï¼‰..."
cd /mnt/petrelfs/liuhaoze/main/xlam_60k

accelerate launch \
    --num_processes 8 \
    --num_machines 1 \
    --mixed_precision no \
    --multi_gpu \
    evaluate_xlam_basic.py \
    --dataset /mnt/petrelfs/liuhaoze/datasets/xlam_60k.jsonl \
    --metric semantic \
    --semantic-model /mnt/petrelfs/liuhaoze/models1/Qwen2.5-32B-Instruct \
    --semantic-max-samples 0 \
    --semantic-batch-size 8 \
    --semantic-max-new-tokens 512 \
    --accelerate

echo -e "\n=========================================="
echo "âœ… ä»»åŠ¡å®Œæˆ"
echo "End Time: $(date)"
echo "=========================================="
echo -e "\nğŸ“ ç»“æœæ–‡ä»¶ä½ç½®:"
echo "   /mnt/petrelfs/liuhaoze/datasets/xlam_60k_eval_logs/base_metric/"
echo "=========================================="


#SBATCH -p TDS
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gres=gpu:8
#SBATCH --cpus-per-task=32
#SBATCH -o logs/basic_eval_%j.out
#SBATCH -e logs/basic_eval_%j.err
#SBATCH --time=12:00:00

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs

echo "=========================================="
echo "ğŸš€ XLam Dataset Semantic Executability Evaluation"
echo "    Dataset: xlam_60k.jsonl (60,000 samples)"
echo "    Metric: Semantic Executability (Full Dataset)"
echo "    Model: Qwen2.5-32B-Instruct"
echo "    GPUs: 8 (Accelerate Multi-GPU)"
echo "    Batch Size: 16"
echo "=========================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURM_JOB_NODELIST"
echo "Start Time: $(date)"
echo "=========================================="

# åˆå§‹åŒ– conda
source ~/anaconda3/etc/profile.d/conda.sh
conda activate base

# éªŒè¯ç¯å¢ƒ
echo -e "\nğŸ” Python ç¯å¢ƒ:"
which python
python --version

echo -e "\nğŸ“¦ æ£€æŸ¥ä¾èµ–:"
pip show transformers torch accelerate || echo "âš ï¸  éœ€è¦å®‰è£…ä¾èµ–"

# æ˜¾ç¤º GPU ä¿¡æ¯
echo -e "\nğŸ“Š GPU ä¿¡æ¯:"
nvidia-smi

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONUNBUFFERED=1
export TOKENIZERS_PARALLELISM=false

# è¿è¡Œå®Œæ•´è¯„ä¼°
echo -e "\nğŸ”¥ å¼€å§‹è¿è¡Œå®Œæ•´åŸºç¡€è¯„ä¼°..."
cd /mnt/petrelfs/liuhaoze/main/xlam_60k

accelerate launch \
    --num_processes 8 \
    --num_machines 1 \
    --mixed_precision no \
    --multi_gpu \
    evaluate_xlam_basic.py \
    --dataset /mnt/petrelfs/liuhaoze/datasets/xlam_60k.jsonl \
    --metric semantic \
    --semantic-model /mnt/petrelfs/liuhaoze/models1/Qwen2.5-32B-Instruct \
    --semantic-max-samples 0 \
    --semantic-batch-size 16 \
    --semantic-max-new-tokens 512 \
    --accelerate

echo -e "\n=========================================="
echo "âœ… ä»»åŠ¡å®Œæˆ"
echo "End Time: $(date)"
echo "=========================================="
echo -e "\nğŸ“ ç»“æœæ–‡ä»¶ä½ç½®:"
echo "   /mnt/petrelfs/liuhaoze/datasets/xlam_60k_eval_logs/base_metric/"
echo "=========================================="





