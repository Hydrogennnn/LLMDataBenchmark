#!/bin/bash
#SBATCH -J safety_ddp
#SBATCH -p TDS
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gres=gpu:8
#SBATCH --cpus-per-task=32
#SBATCH -o logs/safety_ddp_%j.out
#SBATCH -e logs/safety_ddp_%j.err
#SBATCH --time=12:00:00

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs

echo "=========================================="
echo "ğŸš€ Multi-GPU DDP Safety Evaluation"
echo "    Model: Qwen2.5-32B-Instruct"
echo "    GPUs: 8 (çœŸæ­£çš„æ•°æ®å¹¶è¡Œ)"
echo "    Batch per GPU: 8"
echo "=========================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURM_JOB_NODELIST"
echo "Start Time: $(date)"
echo "=========================================="

# åˆå§‹åŒ– conda
source ~/anaconda3/etc/profile.d/conda.sh
conda activate base

# éªŒè¯ç¯å¢ƒ
echo -e "\nğŸ” Python ç¯å¢ƒ:"
which python
python --version

# æ˜¾ç¤º GPU ä¿¡æ¯
echo -e "\nğŸ“Š GPU ä¿¡æ¯:"
nvidia-smi

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONUNBUFFERED=1
export TOKENIZERS_PARALLELISM=false

# è¿è¡Œè¯„ä¼°
echo -e "\nğŸ”¥ å¼€å§‹è¿è¡Œ DDP å®‰å…¨è¯„ä¼°..."
cd /mnt/petrelfs/liuhaoze/main/xlam_60k

python ddp.py \
    --dataset /mnt/petrelfs/liuhaoze/datasets/xlam_60k.jsonl \
    --model /mnt/petrelfs/liuhaoze/models1/Qwen2.5-32B-Instruct \
    --num-gpus 8 \
    --batch-size 8

echo -e "\n=========================================="
echo "âœ… ä»»åŠ¡å®Œæˆ"
echo "End Time: $(date)"
echo "=========================================="

