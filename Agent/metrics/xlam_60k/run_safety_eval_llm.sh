#!/bin/bash
#SBATCH -J safety_eval_llm
#SBATCH -p TDS
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gres=gpu:8
#SBATCH --cpus-per-task=32
#SBATCH -o logs/safety_eval_llm_%j.out
#SBATCH -e logs/safety_eval_llm_%j.err
#SBATCH --time=12:00:00

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs

echo "=========================================="
echo "ğŸ›¡ï¸  Safety Evaluation (SafeToolBench Framework)"
echo "    Model: Qwen2.5-32B-Instruct"
echo "    GPUs: 8 (batch inference)"
echo "=========================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURM_JOB_NODELIST"
echo "Start Time: $(date)"
echo "=========================================="

# åˆå§‹åŒ– conda
source ~/anaconda3/etc/profile.d/conda.sh
conda activate base

# éªŒè¯ç¯å¢ƒ
echo -e "\nğŸ” Python ç¯å¢ƒ:"
which python
python --version

# æ˜¾ç¤º GPU ä¿¡æ¯
echo -e "\nğŸ“Š GPU ä¿¡æ¯:"
nvidia-smi

# è¿è¡Œå®‰å…¨è¯„ä¼°è„šæœ¬ï¼ˆä½¿ç”¨batchæ¨ç†åŠ é€Ÿï¼‰
echo -e "\nğŸ”¥ å¼€å§‹è¿è¡Œå®‰å…¨è¯„ä¼° (batch_size=32)..."
cd /mnt/petrelfs/liuhaoze/main/xlam_60k

python evaluate_xlam_trustworthy_llm.py \
    --dataset /mnt/petrelfs/liuhaoze/datasets/xlam_60k.jsonl \
    --local \
    --model /mnt/petrelfs/liuhaoze/models1/Qwen2.5-32B-Instruct \
    --batch-size 32

echo -e "\n=========================================="
echo "âœ… ä»»åŠ¡å®Œæˆ"
echo "End Time: $(date)"
echo "=========================================="

